{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Download the English Wikipedia Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-09 16:37:55--  https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles1.xml-p1p41242.bz2\n",
      "Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.154.71\n",
      "Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.154.71|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 283332977 (270M) [application/octet-stream]\n",
      "Saving to: 'enwiki_sample.xml.bz2'\n",
      "\n",
      "enwiki_sample.xml.b 100%[===================>] 270.21M  4.35MB/s    in 66s     \n",
      "\n",
      "2024-10-09 16:39:03 (4.09 MB/s) - 'enwiki_sample.xml.bz2' saved [283332977/283332977]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a working directory\n",
    "!mkdir fasttext_language_id\n",
    "!cd fasttext_language_id\n",
    "\n",
    "# Download a sample of the English Wikipedia dump\n",
    "!wget https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles1.xml-p1p41242.bz2 -O enwiki_sample.xml.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install WikiExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'wikiextractor'...\n",
      "remote: Enumerating objects: 771, done.\u001b[K\n",
      "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
      "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
      "remote: Total 771 (delta 17), reused 21 (delta 14), pack-reused 741 (from 1)\u001b[K\n",
      "Receiving objects: 100% (771/771), 1.31 MiB | 4.92 MiB/s, done.\n",
      "Resolving deltas: 100% (450/450), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/attardi/wikiextractor.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Text from the Wikipedia Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Preprocessing '../enwiki_sample.xml.bz2' to collect template definitions: this may take some time.\n",
      "INFO: Loaded 0 templates in 26.7s\n",
      "INFO: Starting page extraction from ../enwiki_sample.xml.bz2.\n",
      "INFO: Using 4 extract processes.\n",
      "WARNING: Template errors in article 'Koan' (16862): title(1) recursion(0, 0, 0)\n",
      "INFO: Finished 4-process extraction of 27140 articles in 59.3s (457.5 art/s)\n"
     ]
    }
   ],
   "source": [
    "!cd wikiextractor && python3 -m wikiextractor.WikiExtractor ../enwiki_sample.xml.bz2 -o ../extracted -b 100M --processes 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data for fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all text files into one\n",
    "!cd extracted &&find . -name 'wiki_*' -exec cat {} + > ../en_text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Labels to Each Line\n",
    "!sed -i '' 's/^/__label__eng /' en_text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__eng <doc id=\"32173\" url=\"https://en.wikipedia.org/wiki?curid=32173\" title=\"United States Military Academy\">\n",
      "__label__eng United States Military Academy\n",
      "__label__eng \n",
      "__label__eng The United States Military Academy (USMA), also referred to metonymically as West Point or simply as Army, is a United States service academy in West Point, New York. It was originally established as a fort during the American Revolutionary War, as it sits on strategic high ground overlooking the Hudson River north of New York City. Founded in 1802, it is the oldest of the five American service academies and educates cadets for commissioning into the United States Army. The academic program grants the Bachelor of Science degree with a curriculum that grades cadets' performance upon a broad academic program, military leadership performance, and mandatory participation in competitive athletics. \n",
      "__label__eng Candidates for admission must apply directly to the academy and receive a nomination, usually from a member of Congress. Other nomination sources include the president and vice president. Students are officers-in-training and are referred to as \"cadets\" or collectively as the \"United States Corps of Cadets\" (USCC). The Army fully funds tuition for cadets in exchange for an active duty service obligation upon graduation. About 1,300 cadets enter the academy each July, with about 1,000 cadets graduating. \n",
      "__label__eng The academy's traditions have influenced other institutions because of its age and unique mission. It was the first American college to have an accredited civil engineering program and the first to have class rings, and its technical curriculum became a model for engineering schools. West Point's student body has a unique rank structure and lexicon. The academy fields 15 men's and nine women's National Collegiate Athletic Association (NCAA) sports teams. Cadets compete in one sport every fall, winter, and spring season at the intramural, club, or intercollegiate level. Its football team was a national power in the early and mid-20th century, winning three national championships. Among the country's public institutions, the academy is the top producer of Marshall and Rhodes scholars. Its alumni are collectively referred to as \"The Long Gray Line,\" which include U.S. Presidents Dwight D. Eisenhower and Ulysses S. Grant; Confederate President Jefferson Davis; Confederate general Robert E. Lee; American poet Edgar Allan Poe; U.S. generals Douglas MacArthur and George Patton; presidents of Costa Rica, Nicaragua, and the Philippines; and 76 Medal of Honor recipients.\n",
      "__label__eng History.\n",
      "__label__eng Colonial period, founding, and early years.\n",
      "__label__eng The Continental Army first occupied West Point, New York, on 27 January 1778, and it is the oldest continuously operating Army post in the United States. Between 1778 and 1780, the Polish engineer and military hero Tadeusz Kościuszko oversaw the construction of the garrison defenses. However, Kościuszko's plan of a system of small forts did not meet with the approval of New York Governor (and General) George Clinton or the other general officers. It was determined that a battery along the river to \"annoy the shipping\" was more appropriate, and Washington's chief engineer, Rufus Putnam, directed the construction of a major fortification on a hill above sea level that commanded the West Point plain. General Alexander McDougall named it Fort Putnam. The Great Hudson River Chain and high ground above the narrow \"S\" curve in the river enabled the Continental Army to prevent the Royal Navy from sailing upriver and dividing Patriot forces in the Northern colonies from the south. While the fortifications at West Point were known as Fort Arnold during the war, as commander, Benedict Arnold committed his act of treason, attempting to turn the fort over to the British. After Arnold betrayed the patriot cause, the Army changed the name of the fortifications at West Point, New York, to Fort Clinton, named after General James Clinton. With the peace after the American Revolutionary War, various ordnance and military stores were left deposited at West Point.\n",
      "__label__eng \"Cadets\" underwent training in artillery and engineering studies at the garrison since 1794. During the Quasi-War, Alexander Hamilton laid out plans for the establishment of a military academy at West Point and introduced \"A Bill for Establishing a Military Academy\" in the House of Representatives. In 1801, shortly after his inauguration as president, Thomas Jefferson directed that plans be set in motion to establish at West Point the United States Military Academy. He selected Jonathan Williams to serve as its first superintendent. Congress formally authorized the establishment and funding of the school with the Military Peace Establishment Act of 1802, which Jefferson signed on 16 March. The academy officially commenced operations on 4 July 1802. The academy graduated Joseph Gardner Swift, its first official graduate, in October 1802. He later returned as Superintendent from 1812 to 1814. In its tumultuous early years, the academy featured few standards for admission or length of study. Cadets ranged in age from 10 years to 37 years and attended between 6 months to 6 years. The impending War of 1812 caused the United States Congress to authorize a more formal system of education at the academy and increased the size of the Corps of Cadets to 250.\n"
     ]
    }
   ],
   "source": [
    "# Let's verify the Data Format\n",
    "!head en_text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning completed. Processed data saved to final_cleaned_text.txt\n"
     ]
    }
   ],
   "source": [
    "# We need to clean the text data before training the model using utility funciton\n",
    "!python3 clean_text.py en_text.txt final_cleaned_text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__eng The United States Military Academy (USMA), also referred to metonymically\n",
      "__label__eng Candidates for admission must apply directly to the academy and\n",
      "__label__eng The academy's traditions have influenced other institutions because of its\n",
      "__label__eng Colonial period, founding, and early years.\n",
      "__label__eng The Continental Army first occupied West Point, New York, on\n",
      "__label__eng \"Cadets\" underwent training in artillery and engineering studies at the\n",
      "__label__eng In 1817, Colonel Sylvanus Thayer became the Superintendent and established\n",
      "__label__eng In 1835, during the Army's first year of the Second\n",
      "__label__eng The Mexican–American War brought the academy to prominence as graduates\n",
      "__label__eng Immediately following the Civil War, the academy enjoyed unprecedented fame\n"
     ]
    }
   ],
   "source": [
    "# Let's verify the Data Format\n",
    "!head final_cleaned_text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__eng The earliest systems employed a spinning disk to create and\n",
      "__label__eng \"And Sousakim gave to Jeroboam Ano the eldest sister of\n",
      "__label__eng According to Leveritt, \"Police records were a mess. To call\n",
      "__label__eng The governorship of the Tendilla-Mondéjar family came to an end\n",
      "__label__eng Euthanasia opponent Ian Dowbiggin argues that the early membership of\n",
      "__label__eng κ Aquarii, also called \"Situla\", has an apparent\n",
      "__label__eng As a non-signatory of the Treaty on Nuclear Non-Proliferation, Pakistan\n",
      "__label__eng Nearby villages and settlements include St. Johnston. McKinnon's Pond is\n",
      "__label__eng Competition keirin races are conducted over several rounds with one\n",
      "__label__eng Tivara, the fourth son of Ashoka and Karuvaki, is the\n"
     ]
    }
   ],
   "source": [
    "# We need to shuffle the data before training the model using utility funciton\n",
    "!shuf final_cleaned_text.txt > shuffled_cleaned_text.txt\n",
    "\n",
    "# Verify the shuffled data by showing the first few lines\n",
    "!head shuffled_cleaned_text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:   622781 lines\n",
      "Test set:   155696 lines\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "# Get the total number of lines and split the dataset\n",
    "!total_lines=$(wc -l < shuffled_cleaned_text.txt) && \\\n",
    "train_lines=$(echo \"$total_lines * 0.8 / 1\" | bc) && \\\n",
    "test_lines=$(echo \"$total_lines - $train_lines\" | bc) && \\\n",
    "head -n $train_lines shuffled_cleaned_text.txt > train.txt && \\\n",
    "tail -n $test_lines shuffled_cleaned_text.txt > test.txt\n",
    "\n",
    "# Verify the split\n",
    "!echo \"Train set: $(wc -l < train.txt) lines\"\n",
    "!echo \"Test set: $(wc -l < test.txt) lines\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Build fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-09 16:33:09--  https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\n",
      "Resolving github.com (github.com)... 4.237.22.38\n",
      "Connecting to github.com (github.com)|4.237.22.38|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://codeload.github.com/facebookresearch/fastText/zip/refs/tags/v0.9.2 [following]\n",
      "--2024-10-09 16:33:09--  https://codeload.github.com/facebookresearch/fastText/zip/refs/tags/v0.9.2\n",
      "Resolving codeload.github.com (codeload.github.com)... 4.237.22.35\n",
      "Connecting to codeload.github.com (codeload.github.com)|4.237.22.35|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: 'v0.9.2.zip.3'\n",
      "\n",
      "v0.9.2.zip.3            [     <=>            ]   4.17M  4.12MB/s    in 1.0s    \n",
      "\n",
      "2024-10-09 16:33:11 (4.12 MB/s) - 'v0.9.2.zip.3' saved [4369852]\n",
      "\n",
      "Archive:  v0.9.2.zip\n",
      "5b5943c118b0ec5fb9cd8d20587de2b2d3966dfe\n",
      "   creating: fastText-0.9.2/\n",
      "   creating: fastText-0.9.2/.circleci/\n",
      "  inflating: fastText-0.9.2/.circleci/cmake_test.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/config.yml  \n",
      "  inflating: fastText-0.9.2/.circleci/gcc_test.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/pip_test.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/pull_data.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/python_test.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/run_locally.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/setup_circleimg.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/setup_debian.sh  \n",
      "  inflating: fastText-0.9.2/.gitignore  \n",
      "  inflating: fastText-0.9.2/CMakeLists.txt  \n",
      "  inflating: fastText-0.9.2/CODE_OF_CONDUCT.md  \n",
      "  inflating: fastText-0.9.2/CONTRIBUTING.md  \n",
      "  inflating: fastText-0.9.2/LICENSE  \n",
      "  inflating: fastText-0.9.2/MANIFEST.in  \n",
      "  inflating: fastText-0.9.2/Makefile  \n",
      "  inflating: fastText-0.9.2/README.md  \n",
      "   creating: fastText-0.9.2/alignment/\n",
      "  inflating: fastText-0.9.2/alignment/README.md  \n",
      "  inflating: fastText-0.9.2/alignment/align.py  \n",
      "  inflating: fastText-0.9.2/alignment/eval.py  \n",
      "  inflating: fastText-0.9.2/alignment/example.sh  \n",
      "  inflating: fastText-0.9.2/alignment/unsup_align.py  \n",
      "  inflating: fastText-0.9.2/alignment/unsup_multialign.py  \n",
      "  inflating: fastText-0.9.2/alignment/utils.py  \n",
      "  inflating: fastText-0.9.2/classification-example.sh  \n",
      "  inflating: fastText-0.9.2/classification-results.sh  \n",
      "   creating: fastText-0.9.2/crawl/\n",
      "  inflating: fastText-0.9.2/crawl/README.md  \n",
      "  inflating: fastText-0.9.2/crawl/dedup.cc  \n",
      "  inflating: fastText-0.9.2/crawl/download_crawl.sh  \n",
      "  inflating: fastText-0.9.2/crawl/filter_dedup.sh  \n",
      "  inflating: fastText-0.9.2/crawl/filter_utf8.cc  \n",
      "  inflating: fastText-0.9.2/crawl/process_wet_file.sh  \n",
      "   creating: fastText-0.9.2/docs/\n",
      "  inflating: fastText-0.9.2/docs/aligned-vectors.md  \n",
      "  inflating: fastText-0.9.2/docs/api.md  \n",
      "  inflating: fastText-0.9.2/docs/autotune.md  \n",
      "  inflating: fastText-0.9.2/docs/cheatsheet.md  \n",
      "  inflating: fastText-0.9.2/docs/crawl-vectors.md  \n",
      "  inflating: fastText-0.9.2/docs/dataset.md  \n",
      "  inflating: fastText-0.9.2/docs/english-vectors.md  \n",
      "  inflating: fastText-0.9.2/docs/faqs.md  \n",
      "  inflating: fastText-0.9.2/docs/language-identification.md  \n",
      "  inflating: fastText-0.9.2/docs/options.md  \n",
      "  inflating: fastText-0.9.2/docs/pretrained-vectors.md  \n",
      "  inflating: fastText-0.9.2/docs/python-module.md  \n",
      "  inflating: fastText-0.9.2/docs/references.md  \n",
      "  inflating: fastText-0.9.2/docs/supervised-models.md  \n",
      "  inflating: fastText-0.9.2/docs/supervised-tutorial.md  \n",
      "  inflating: fastText-0.9.2/docs/support.md  \n",
      "  inflating: fastText-0.9.2/docs/unsupervised-tutorials.md  \n",
      "  inflating: fastText-0.9.2/docs/webassembly-module.md  \n",
      "  inflating: fastText-0.9.2/download_model.py  \n",
      "  inflating: fastText-0.9.2/eval.py  \n",
      "  inflating: fastText-0.9.2/fasttext.pc.in  \n",
      "  inflating: fastText-0.9.2/get-wikimedia.sh  \n",
      "   creating: fastText-0.9.2/python/\n",
      "  inflating: fastText-0.9.2/python/README.md  \n",
      "  inflating: fastText-0.9.2/python/README.rst  \n",
      "   creating: fastText-0.9.2/python/benchmarks/\n",
      "  inflating: fastText-0.9.2/python/benchmarks/README.rst  \n",
      "  inflating: fastText-0.9.2/python/benchmarks/get_word_vector.py  \n",
      "   creating: fastText-0.9.2/python/doc/\n",
      "   creating: fastText-0.9.2/python/doc/examples/\n",
      "  inflating: fastText-0.9.2/python/doc/examples/FastTextEmbeddingBag.py  \n",
      "  inflating: fastText-0.9.2/python/doc/examples/bin_to_vec.py  \n",
      "  inflating: fastText-0.9.2/python/doc/examples/compute_accuracy.py  \n",
      "  inflating: fastText-0.9.2/python/doc/examples/get_vocab.py  \n",
      "  inflating: fastText-0.9.2/python/doc/examples/train_supervised.py  \n",
      "  inflating: fastText-0.9.2/python/doc/examples/train_unsupervised.py  \n",
      "   creating: fastText-0.9.2/python/fasttext_module/\n",
      "   creating: fastText-0.9.2/python/fasttext_module/fasttext/\n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/FastText.py  \n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/__init__.py  \n",
      "   creating: fastText-0.9.2/python/fasttext_module/fasttext/pybind/\n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/pybind/fasttext_pybind.cc  \n",
      "   creating: fastText-0.9.2/python/fasttext_module/fasttext/tests/\n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/__init__.py  \n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/test_configurations.py  \n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/test_script.py  \n",
      "   creating: fastText-0.9.2/python/fasttext_module/fasttext/util/\n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/util/__init__.py  \n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/util/util.py  \n",
      "  inflating: fastText-0.9.2/quantization-example.sh  \n",
      "  inflating: fastText-0.9.2/reduce_model.py  \n",
      "  inflating: fastText-0.9.2/runtests.py  \n",
      "   creating: fastText-0.9.2/scripts/\n",
      "   creating: fastText-0.9.2/scripts/kbcompletion/\n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/README.md  \n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/data.sh  \n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/eval.cpp  \n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/fb15k.sh  \n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/fb15k237.sh  \n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/svo.sh  \n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/wn18.sh  \n",
      "   creating: fastText-0.9.2/scripts/quantization/\n",
      "  inflating: fastText-0.9.2/scripts/quantization/quantization-results.sh  \n",
      " extracting: fastText-0.9.2/setup.cfg  \n",
      "  inflating: fastText-0.9.2/setup.py  \n",
      "   creating: fastText-0.9.2/src/\n",
      "  inflating: fastText-0.9.2/src/args.cc  \n",
      "  inflating: fastText-0.9.2/src/args.h  \n",
      "  inflating: fastText-0.9.2/src/autotune.cc  \n",
      "  inflating: fastText-0.9.2/src/autotune.h  \n",
      "  inflating: fastText-0.9.2/src/densematrix.cc  \n",
      "  inflating: fastText-0.9.2/src/densematrix.h  \n",
      "  inflating: fastText-0.9.2/src/dictionary.cc  \n",
      "  inflating: fastText-0.9.2/src/dictionary.h  \n",
      "  inflating: fastText-0.9.2/src/fasttext.cc  \n",
      "  inflating: fastText-0.9.2/src/fasttext.h  \n",
      "  inflating: fastText-0.9.2/src/loss.cc  \n",
      "  inflating: fastText-0.9.2/src/loss.h  \n",
      "  inflating: fastText-0.9.2/src/main.cc  \n",
      "  inflating: fastText-0.9.2/src/matrix.cc  \n",
      "  inflating: fastText-0.9.2/src/matrix.h  \n",
      "  inflating: fastText-0.9.2/src/meter.cc  \n",
      "  inflating: fastText-0.9.2/src/meter.h  \n",
      "  inflating: fastText-0.9.2/src/model.cc  \n",
      "  inflating: fastText-0.9.2/src/model.h  \n",
      "  inflating: fastText-0.9.2/src/productquantizer.cc  \n",
      "  inflating: fastText-0.9.2/src/productquantizer.h  \n",
      "  inflating: fastText-0.9.2/src/quantmatrix.cc  \n",
      "  inflating: fastText-0.9.2/src/quantmatrix.h  \n",
      "  inflating: fastText-0.9.2/src/real.h  \n",
      "  inflating: fastText-0.9.2/src/utils.cc  \n",
      "  inflating: fastText-0.9.2/src/utils.h  \n",
      "  inflating: fastText-0.9.2/src/vector.cc  \n",
      "  inflating: fastText-0.9.2/src/vector.h  \n",
      "   creating: fastText-0.9.2/tests/\n",
      "  inflating: fastText-0.9.2/tests/fetch_test_data.sh  \n",
      "   creating: fastText-0.9.2/webassembly/\n",
      "  inflating: fastText-0.9.2/webassembly/README.md  \n",
      "   creating: fastText-0.9.2/webassembly/doc/\n",
      "   creating: fastText-0.9.2/webassembly/doc/examples/\n",
      "  inflating: fastText-0.9.2/webassembly/doc/examples/misc.html  \n",
      "  inflating: fastText-0.9.2/webassembly/doc/examples/predict.html  \n",
      "  inflating: fastText-0.9.2/webassembly/doc/examples/train_supervised.html  \n",
      "  inflating: fastText-0.9.2/webassembly/doc/examples/train_unsupervised.html  \n",
      "  inflating: fastText-0.9.2/webassembly/fasttext.js  \n",
      "  inflating: fastText-0.9.2/webassembly/fasttext_wasm.cc  \n",
      "   creating: fastText-0.9.2/website/\n",
      "  inflating: fastText-0.9.2/website/README.md  \n",
      "   creating: fastText-0.9.2/website/blog/\n",
      "  inflating: fastText-0.9.2/website/blog/2016-08-18-blog-post.md  \n",
      "  inflating: fastText-0.9.2/website/blog/2017-05-02-blog-post.md  \n",
      "  inflating: fastText-0.9.2/website/blog/2017-10-02-blog-post.md  \n",
      "  inflating: fastText-0.9.2/website/blog/2019-06-25-blog-post.md  \n",
      "   creating: fastText-0.9.2/website/core/\n",
      "  inflating: fastText-0.9.2/website/core/Footer.js  \n",
      "  inflating: fastText-0.9.2/website/package.json  \n",
      "   creating: fastText-0.9.2/website/pages/\n",
      "   creating: fastText-0.9.2/website/pages/en/\n",
      "  inflating: fastText-0.9.2/website/pages/en/index.js  \n",
      "  inflating: fastText-0.9.2/website/sidebars.json  \n",
      "  inflating: fastText-0.9.2/website/siteConfig.js  \n",
      "   creating: fastText-0.9.2/website/static/\n",
      "   creating: fastText-0.9.2/website/static/docs/\n",
      "   creating: fastText-0.9.2/website/static/docs/en/\n",
      "   creating: fastText-0.9.2/website/static/docs/en/html/\n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/.classfasttext_1_1QMatrix-members.html.i4eKqy  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/annotated.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/annotated_dup.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h_source.html  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/bc_s.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/bdwn.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classes.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/closed.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dir_68267d1309a1af8e8297ef4c3efbcdba.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dir_68267d1309a1af8e8297ef4c3efbcdba.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/doc.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/doxygen.css  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/doxygen.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dynsections.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/favicon.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/files.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/files.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/folderclosed.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/folderopen.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_0x7e.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_b.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_c.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_d.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_dup.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_e.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_f.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_func.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_g.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_i.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_k.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_l.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_m.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_n.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_o.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_p.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_q.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_r.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_s.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_t.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_u.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_v.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_vars.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_w.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_z.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/globals.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/globals_defs.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/globals_func.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/index.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/jquery.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/main_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/main_8cc.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/menu.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/menudata.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext_1_1utils.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_enum.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_func.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_type.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespaces.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespaces.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/nav_f.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/nav_g.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/nav_h.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/navtree.css  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/navtree.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreedata.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreeindex0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreeindex1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/open.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8cc.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/resize.js  \n",
      "   creating: fastText-0.9.2/website/static/docs/en/html/search/\n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/search/.files_7.html.StRRNc  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/search/.variables_a.html.1MGQ27  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_10.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_10.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_11.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_11.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_12.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_12.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_13.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_13.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_14.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_14.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_15.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_15.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_16.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_16.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_17.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_17.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_4.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_4.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_5.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_5.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_6.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_6.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_7.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_7.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_8.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_8.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_9.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_9.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_a.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_a.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_b.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_b.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_c.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_c.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_d.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_d.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_e.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_e.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_f.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_f.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_4.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_4.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_5.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_5.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_6.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_6.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_7.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_7.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_8.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_8.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/search/close.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_4.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_4.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_5.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_5.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_4.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_4.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_5.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_5.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_6.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_6.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_7.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_7.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_8.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_8.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_10.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_10.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_11.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_11.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_12.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_12.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_13.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_13.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_14.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_14.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_15.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_15.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_16.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_16.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_17.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_17.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_4.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_4.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_5.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_5.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_6.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_6.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_7.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_7.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_8.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_8.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_9.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_9.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_a.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_a.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_b.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_b.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_c.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_c.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_d.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_d.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_e.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_e.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_f.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_f.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/search/mag_sel.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/namespaces_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/namespaces_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/nomatches.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search.css  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/search/search_l.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search_m.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/search/search_r.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/searchdata.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_10.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_10.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_11.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_11.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_12.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_12.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_13.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_13.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_4.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_4.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_5.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_5.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_6.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_6.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_7.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_7.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_8.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_8.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_9.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_9.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_a.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_a.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_b.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_b.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_c.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_c.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_d.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_d.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_e.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_e.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_f.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_f.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/splitbar.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/sync_off.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/sync_on.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/tab_a.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/tab_b.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/tab_h.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/tab_s.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/tabs.css  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8cc.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8cc.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/fasttext.css  \n",
      "   creating: fastText-0.9.2/website/static/img/\n",
      "   creating: fastText-0.9.2/website/static/img/authors/\n",
      "  inflating: fastText-0.9.2/website/static/img/authors/armand_joulin.jpg  \n",
      "  inflating: fastText-0.9.2/website/static/img/authors/christian_puhrsch.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/authors/edouard_grave.jpeg  \n",
      "  inflating: fastText-0.9.2/website/static/img/authors/piotr_bojanowski.jpg  \n",
      "  inflating: fastText-0.9.2/website/static/img/authors/tomas_mikolov.jpg  \n",
      "   creating: fastText-0.9.2/website/static/img/blog/\n",
      "  inflating: fastText-0.9.2/website/static/img/blog/2016-08-18-blog-post-img1.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/blog/2016-08-18-blog-post-img2.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/blog/2017-05-02-blog-post-img1.jpg  \n",
      "  inflating: fastText-0.9.2/website/static/img/blog/2017-05-02-blog-post-img2.jpg  \n",
      "  inflating: fastText-0.9.2/website/static/img/blog/2017-10-02-blog-post-img1.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/cbo_vs_skipgram.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-api.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-bg-web.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-color-square.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-color-web.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-faq.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-tutorial.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-white-web.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-logo-color-web.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-logo-white-web.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/logo-color.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/model-black.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/model-blue.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/model-red.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/ogimage.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/oss_logo.png  \n",
      "  inflating: fastText-0.9.2/website/static/tabber.js  \n",
      "  inflating: fastText-0.9.2/wikifil.pl  \n",
      "  inflating: fastText-0.9.2/word-vector-example.sh  \n"
     ]
    }
   ],
   "source": [
    "# Downloading fastText\n",
    "!wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\n",
    "!unzip v0.9.2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ruslankhissamiyev/Desktop/ADS Final Presentation/ADSFinal/fastText-0.9.2\n",
      "make: Nothing to be done for `opt'.\n"
     ]
    }
   ],
   "source": [
    "# Moving to the fastText directory and building it\n",
    "!cd fastText-0.9.2\n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: fasttext <command> <args>\n",
      "\n",
      "The commands supported by fasttext are:\n",
      "\n",
      "  supervised              train a supervised classifier\n",
      "  quantize                quantize a model to reduce the memory usage\n",
      "  test                    evaluate a supervised classifier\n",
      "  test-label              print labels with precision and recall scores\n",
      "  predict                 predict most likely labels\n",
      "  predict-prob            predict most likely labels with probabilities\n",
      "  skipgram                train a skipgram model\n",
      "  cbow                    train a cbow model\n",
      "  print-word-vectors      print word vectors given a trained model\n",
      "  print-sentence-vectors  print sentence vectors given a trained model\n",
      "  print-ngrams            print ngrams given a trained model and word\n",
      "  nn                      query for nearest neighbors\n",
      "  analogies               query for analogies\n",
      "  dump                    dump arguments,dictionary,input/output vectors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing if fastText is working\n",
    "!./fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 7M words\n",
      "Number of words:  377291\n",
      "Number of labels: 1\n",
      "Progress: 100.0% words/sec/thread: 3271998 lr:  0.000000 avg.loss:  0.000000 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "!fastText-0.9.2/fasttext supervised -input train.txt -output langdetect -dim 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t1480\n",
      "P@1\t1\n",
      "R@1\t1\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "!fastText-0.9.2/fasttext test langdetect.bin test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop Over Each Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't run this code as it will take around 4 days to download and process all the languages >> Use code below instead\n",
    "# Prepare the Main Document\n",
    "!touch all_languages_text.txt\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import shlex\n",
    "\n",
    "def process_language(lang):\n",
    "    print(f\"Processing language: {lang}\")\n",
    "    \n",
    "    parent_dir = os.getcwd()\n",
    "    working_dir = os.path.join(parent_dir, f\"{lang}_fasttext_language_id\")\n",
    "    os.makedirs(working_dir, exist_ok=True)\n",
    "    \n",
    "    dump_file = f\"{lang}wiki-latest-pages-articles.xml.bz2\"\n",
    "    dump_url = f\"https://dumps.wikimedia.org/{lang}wiki/latest/{dump_file}\"\n",
    "    \n",
    "    # Download with retry\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Downloading dump for {lang} (Attempt {attempt + 1}/{max_retries})\")\n",
    "            subprocess.run(f\"wget {dump_url} -O {dump_file}\", shell=True, cwd=working_dir, check=True)\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"Failed to download dump for {lang} after {max_retries} attempts. Skipping.\")\n",
    "                return\n",
    "            print(f\"Download failed, retrying in 5 seconds...\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    clean_script_path = \"/Users/ruslankhissamiyev/Desktop/ADS Final Presentation/ADSFinal/clean_text.py\"\n",
    "    \n",
    "    steps = [\n",
    "        (\"extraction\", f\"python3 -m wikiextractor.WikiExtractor {dump_file} -o extracted --processes 4\"),\n",
    "        (\"combination\", \"find extracted -name 'wiki_*' -exec cat {} + > text.txt\"),\n",
    "        (\"labeling\", f\"sed -i '' 's/^/__label__{lang} /' text.txt\"),\n",
    "        (\"cleaning\", f\"python3 {shlex.quote(clean_script_path)} text.txt cleaned_text.txt\"),\n",
    "        (\"appending\", f\"cat cleaned_text.txt >> {shlex.quote(os.path.join(parent_dir, 'all_languages_text.txt'))}\")\n",
    "    ]\n",
    "    \n",
    "    for step_name, command in steps:\n",
    "        print(f\"Starting {step_name} for {lang}\")\n",
    "        try:\n",
    "            subprocess.run(command, shell=True, cwd=working_dir, check=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to {step_name} for {lang}. Error: {e}\")\n",
    "            return\n",
    "    \n",
    "    print(f\"Completed processing for {lang}\")\n",
    "\n",
    "# List of languages to process\n",
    "languages = [\"en\", \"es\", \"zh\", \"ar\", \"kk\"] \n",
    "\n",
    "# Ensure the main output file exists\n",
    "open('all_languages_text.txt', 'a').close()\n",
    "\n",
    "# Process each language\n",
    "for lang in languages:\n",
    "    process_language(lang)\n",
    "\n",
    "print(\"All languages processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading articles for language: en\n",
      "Collected 100 articles for language en.\n",
      "Downloading articles for language: zh\n",
      "Collected 100 articles for language zh.\n",
      "Downloading articles for language: es\n",
      "Collected 100 articles for language es.\n",
      "Downloading articles for language: ar\n",
      "Collected 100 articles for language ar.\n",
      "Downloading articles for language: fr\n",
      "Collected 100 articles for language fr.\n",
      "Downloading articles for language: ru\n",
      "Collected 100 articles for language ru.\n",
      "Downloading articles for language: pt\n",
      "Collected 100 articles for language pt.\n",
      "Downloading articles for language: de\n",
      "Collected 100 articles for language de.\n",
      "Downloading articles for language: ja\n",
      "Collected 100 articles for language ja.\n",
      "Downloading articles for language: hi\n",
      "Collected 100 articles for language hi.\n",
      "Downloading articles for language: kk\n",
      "Collected 100 articles for language kk.\n",
      "All languages processed.\n"
     ]
    }
   ],
   "source": [
    "# We run this code to download and process the data for all languages >> it produces less data but is faster\n",
    "# Prepare the Main Document\n",
    "!touch all_languages_text.txt\n",
    "\n",
    "languages = [\"en\", \"zh\", \"es\", \"ar\", \"fr\", \"ru\", \"pt\", \"de\", \"ja\", \"hi\", \"kk\"]\n",
    "\n",
    "num_articles_per_language = 100  # Desired number of articles per language\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "\n",
    "def download_random_articles(lang, num_articles, output_file):\n",
    "    base_url = f\"https://{lang}.wikipedia.org/w/api.php\"\n",
    "    session = requests.Session()\n",
    "    headers = {'User-Agent': 'LanguageDetectionBot/1.0 (khissamiyev@gmail.com)'}\n",
    "    articles_per_request = 5  # Adjusted to the actual limit imposed by the API\n",
    "\n",
    "    articles_collected = 0  # Counter for the number of articles collected\n",
    "\n",
    "    while articles_collected < num_articles:\n",
    "        rnlimit = min(articles_per_request, num_articles - articles_collected)\n",
    "\n",
    "        # Step 1: Get random page IDs\n",
    "        params = {\n",
    "            'action': 'query',\n",
    "            'list': 'random',\n",
    "            'rnnamespace': 0,\n",
    "            'rnlimit': rnlimit,\n",
    "            'format': 'json'\n",
    "        }\n",
    "\n",
    "        response = session.get(url=base_url, params=params, headers=headers)\n",
    "        data = response.json()\n",
    "        random_pages = data.get('query', {}).get('random', [])\n",
    "\n",
    "        if not random_pages:\n",
    "            print(f\"Failed to get random pages for language {lang}.\")\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "        page_ids = [str(page['id']) for page in random_pages]\n",
    "\n",
    "        # Step 2: Get content of pages\n",
    "        params = {\n",
    "            'action': 'query',\n",
    "            'prop': 'extracts',\n",
    "            'explaintext': True,\n",
    "            'exlimit': 'max',\n",
    "            'pageids': '|'.join(page_ids),\n",
    "            'format': 'json'\n",
    "        }\n",
    "\n",
    "        response = session.get(url=base_url, params=params, headers=headers)\n",
    "        data = response.json()\n",
    "\n",
    "        if 'query' not in data or 'pages' not in data['query']:\n",
    "            print(f\"Failed to get page extracts for language {lang}.\")\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "        pages = data['query']['pages']\n",
    "        for page_id, page_content in pages.items():\n",
    "            text = page_content.get('extract', '').strip()\n",
    "            if text:\n",
    "                # Clean the text if necessary\n",
    "                cleaned_text = text.replace('\\n', ' ').strip()\n",
    "                # Ensure the line has at least 5 words\n",
    "                if len(cleaned_text.split()) >= 5:\n",
    "                    # Limit the line to 10 words\n",
    "                    limited_text = ' '.join(cleaned_text.split()[:50])\n",
    "                    # Write to file with label\n",
    "                    with open(output_file, 'a', encoding='utf-8') as f_out:\n",
    "                        f_out.write(f\"__label__{lang} {limited_text}\\n\")\n",
    "                    articles_collected += 1  # Increment the counter\n",
    "\n",
    "                    # Break the loop if we've collected enough articles\n",
    "                    if articles_collected >= num_articles:\n",
    "                        break\n",
    "\n",
    "        time.sleep(1)  # Be polite and don't overload the server\n",
    "\n",
    "    print(f\"Collected {articles_collected} articles for language {lang}.\")\n",
    "\n",
    "output_file = 'all_languages_text.txt'\n",
    "\n",
    "for lang in languages:\n",
    "    print(f\"Downloading articles for language: {lang}\")\n",
    "    download_random_articles(lang, num_articles_per_language, output_file)\n",
    "\n",
    "print(\"All languages processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning completed. Processed data saved to final_all_languages_text.txt\n"
     ]
    }
   ],
   "source": [
    "# Applying cleaning function\n",
    "!python3 clean_text.py all_languages_text.txt final_all_languages_text.txt\n",
    "\n",
    "# Resaving data\n",
    "!mv final_all_languages_text.txt all_languages_text.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to shuffle the data before training the model using utility funciton\n",
    "!shuf all_languages_text.txt > shuffled_all_languages_text.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into Training and Testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:      880 lines\n",
      "Test set:      220 lines\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "# Get the total number of lines and split the dataset\n",
    "!total_lines=$(wc -l < shuffled_all_languages_text.txt) && \\\n",
    "train_lines=$(echo \"$total_lines * 0.8 / 1\" | bc) && \\\n",
    "test_lines=$(echo \"$total_lines - $train_lines\" | bc) && \\\n",
    "head -n $train_lines shuffled_all_languages_text.txt > train.txt && \\\n",
    "tail -n $test_lines shuffled_all_languages_text.txt > test.txt\n",
    "\n",
    "# Verify the split\n",
    "!echo \"Train set: $(wc -l < train.txt) lines\"\n",
    "!echo \"Test set: $(wc -l < test.txt) lines\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  20540\n",
      "Number of labels: 11\n",
      "Progress: 100.0% words/sec/thread:  169841 lr:  0.000000 avg.loss:  2.331928 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "!fastText-0.9.2/fasttext supervised -input train.txt -output langdetect -dim 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t220\n",
      "P@1\t0.268\n",
      "R@1\t0.268\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "!fastText-0.9.2/fasttext test langdetect.bin test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  20540\n",
      "Number of labels: 11\n",
      "Progress: 100.0% words/sec/thread:  485883 lr:  0.000000 avg.loss:  0.711034 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./fastText-0.9.2/fasttext', 'supervised', '-input', 'train.txt', '-output', 'langdetect', '-dim', '16', '-epoch', '15', '-lr', '1.0', '-loss', 'hs', '-minn', '2', '-maxn', '4', '-wordNgrams', '2'], returncode=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retraining the model with all improvements applied\n",
    "import subprocess\n",
    "\n",
    "# Command to run FastText with all the improvements applied\n",
    "command = [\n",
    "    './fastText-0.9.2/fasttext', 'supervised',\n",
    "    '-input', 'train.txt',        # Training data\n",
    "    '-output', 'langdetect',      # Output model name prefix\n",
    "    '-dim', '16',                 # Set vector dimension to 16\n",
    "    '-epoch', '15',               # Increase the number of epochs to 15\n",
    "    '-lr', '1.0',                 # Increase the learning rate to 1.0\n",
    "    '-loss', 'hs',                # Use hierarchical softmax loss function\n",
    "    '-minn', '2', '-maxn', '4',   # Use character n-grams from 2 to 4 characters (subword features)\n",
    "    '-wordNgrams', '2'            # Include word bigrams (word n-grams of length 2)\n",
    "]\n",
    "\n",
    "# Run the command using subprocess\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t220\n",
      "P@1\t0.95\n",
      "R@1\t0.95\n"
     ]
    }
   ],
   "source": [
    "# Testing the improved model on the validation set\n",
    "!fastText-0.9.2/fasttext test langdetect.bin test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Started working with OSCAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.32.2\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]<=2024.6.1,>=2023.1.0\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m935.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.6.0)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.17-py39-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.23.5)\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-17.0.0-cp39-cp39-macosx_10_15_x86_64.whl (29.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.22.0\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Collecting tqdm>=4.66.3\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-macosx_10_9_x86_64.whl (31 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.22.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (1.26.11)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, tqdm, requests, pyarrow, fsspec, dill, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.1\n",
      "    Uninstalling tqdm-4.64.1:\n",
      "      Successfully uninstalled tqdm-4.64.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.7.1\n",
      "    Uninstalling fsspec-2022.7.1:\n",
      "      Successfully uninstalled fsspec-2022.7.1\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.4\n",
      "    Uninstalling dill-0.3.4:\n",
      "      Successfully uninstalled dill-0.3.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.20 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.20 requires nbformat==5.4.0, but you have nbformat 5.5.0 which is incompatible.\n",
      "conda-repo-cli 1.0.20 requires requests==2.28.1, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.0.1 dill-0.3.8 fsspec-2024.6.1 huggingface-hub-0.25.2 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 tqdm-4.66.5 xxhash-3.5.0\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "# Downloading the dataset\n",
    "!pip install datasets\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_language(lang, max_size_bytes=2 * 1024 * 1024):\n",
    "    print(f\"Processing language: {lang}\")\n",
    "    try:\n",
    "        # Load the dataset for the language and specify the split\n",
    "        dataset = load_dataset(\"oscar\", f\"unshuffled_deduplicated_{lang}\", split='train', streaming=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Language {lang} is not available in the OSCAR dataset or an error occurred: {e}\")\n",
    "        return\n",
    "\n",
    "    output_file = f\"{lang}_data.txt\"\n",
    "    bytes_written = 0\n",
    "    max_bytes = max_size_bytes  # 100MB limit\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "        # Use tqdm for progress bar\n",
    "        for example in tqdm(dataset, desc=f\"Processing {lang}\"):\n",
    "            text = example['text'].strip()\n",
    "            # Clean the text (you can adjust the regex as needed)\n",
    "            cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "            # Ensure the line has at least 5 words\n",
    "            words = cleaned_text.split()\n",
    "            if len(words) >= 5:\n",
    "                # Limit the line to 10 words\n",
    "                limited_text = ' '.join(words[:10])\n",
    "                # Prepare the line with label\n",
    "                line = f\"__label__{lang} {limited_text}\\n\"\n",
    "                # Write to file\n",
    "                f_out.write(line)\n",
    "                bytes_written += len(line.encode('utf-8'))\n",
    "                # Check if the size limit is reached\n",
    "                if bytes_written >= max_bytes:\n",
    "                    print(f\"Reached 100MB limit for {lang}\")\n",
    "                    break\n",
    "    # Run your existing clean_text.py script\n",
    "    os.system(f\"python3 clean_text.py {output_file} cleaned_{output_file}\")\n",
    "    # Remove the uncleaned file to save space\n",
    "    os.remove(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old list of languages\n",
    "languages = [\n",
    "    \"af\", \"als\", \"am\", \"an\", \"ar\", \"arz\", \"as\", \"ast\", \"av\", \"az\", \"azb\", \"ba\", \"bar\", \"bcl\",\n",
    "    \"be\", \"bg\", \"bh\", \"bn\", \"bo\", \"bpy\", \"br\", \"bs\", \"bxr\", \"ca\", \"cbk\", \"ce\", \"ceb\", \"ckb\",\n",
    "    \"co\", \"cs\", \"cv\", \"cy\", \"da\", \"de\", \"diq\", \"dsb\", \"dty\", \"dv\", \"el\", \"eml\", \"en\", \"eo\",\n",
    "    \"es\", \"et\", \"eu\", \"fa\", \"fi\", \"fr\", \"frr\", \"fy\", \"ga\", \"gd\", \"gl\", \"gn\", \"gom\", \"gu\",\n",
    "    \"gv\", \"he\", \"hi\", \"hif\", \"hr\", \"hsb\", \"ht\", \"hu\", \"hy\", \"ia\", \"id\", \"ie\", \"ilo\", \"io\",\n",
    "    \"is\", \"it\", \"ja\", \"jbo\", \"jv\", \"ka\", \"kk\", \"km\", \"kn\", \"ko\", \"krc\", \"ku\", \"kv\", \"kw\",\n",
    "    \"ky\", \"la\", \"lb\", \"lez\", \"li\", \"lmo\", \"lo\", \"lrc\", \"lt\", \"lv\", \"mai\", \"mg\", \"mhr\",\n",
    "    \"min\", \"mk\", \"ml\", \"mn\", \"mr\", \"mrj\", \"ms\", \"mt\", \"mwl\", \"my\", \"myv\", \"mzn\", \"nah\",\n",
    "    \"nap\", \"nds\", \"ne\", \"new\", \"nl\", \"nn\", \"no\", \"oc\", \"or\", \"os\", \"pa\", \"pam\", \"pfl\", \"pl\",\n",
    "    \"pms\", \"pnb\", \"ps\", \"pt\", \"qu\", \"rm\", \"ro\", \"ru\", \"rue\", \"sa\", \"sah\", \"sc\", \"scn\",\n",
    "    \"sco\", \"sd\", \"sh\", \"si\", \"sk\", \"sl\", \"so\", \"sq\", \"sr\", \"su\", \"sv\", \"sw\", \"ta\", \"te\",\n",
    "    \"tg\", \"th\", \"tk\", \"tl\", \"tr\", \"tt\", \"tyv\", \"ug\", \"uk\", \"ur\", \"uz\", \"vec\", \"vep\", \"vi\",\n",
    "    \"vls\", \"vo\", \"wa\", \"war\", \"wuu\", \"xal\", \"xmf\", \"yi\", \"yo\", \"yue\", \"zh\"\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing language: en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing en: 11010it [00:52, 1163.88it/s]Got disconnected from remote data host. Retrying in 5sec [1/20]\n",
      "Processing en: 28730it [02:36, 183.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100MB limit for en\n",
      "Cleaning completed. Processed data saved to cleaned_en_data.txt\n",
      "Processing language: zh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing zh: 1705it [00:26, 65.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100MB limit for zh\n",
      "Cleaning completed. Processed data saved to cleaned_zh_data.txt\n",
      "Processing language: es\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing es: 16670it [00:59, 163.41it/s] Got disconnected from remote data host. Retrying in 5sec [1/20]\n",
      "Processing es: 27880it [01:41, 274.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100MB limit for es\n",
      "Cleaning completed. Processed data saved to cleaned_es_data.txt\n",
      "Processing language: ar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ar: 17516it [00:43, 401.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100MB limit for ar\n",
      "Cleaning completed. Processed data saved to cleaned_ar_data.txt\n",
      "Processing language: fr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fr: 27089it [00:18, 1478.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100MB limit for fr\n",
      "Cleaning completed. Processed data saved to cleaned_fr_data.txt\n",
      "Processing language: ru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ru: 14189it [00:18, 785.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100MB limit for ru\n",
      "Cleaning completed. Processed data saved to cleaned_ru_data.txt\n",
      "Processing language: pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pt: 27694it [00:20, 1351.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100MB limit for pt\n",
      "Cleaning completed. Processed data saved to cleaned_pt_data.txt\n",
      "Processing language: de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing de: 24365it [00:21, 1141.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100MB limit for de\n",
      "Cleaning completed. Processed data saved to cleaned_de_data.txt\n",
      "Processing language: ja\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ja: 2417it [00:15, 160.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100MB limit for ja\n",
      "Cleaning completed. Processed data saved to cleaned_ja_data.txt\n",
      "Processing language: hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing hi: 14300it [00:22, 648.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100MB limit for hi\n",
      "Cleaning completed. Processed data saved to cleaned_hi_data.txt\n",
      "Processing language: kk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing kk: 13100it [00:12, 1026.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 100MB limit for kk\n",
      "Cleaning completed. Processed data saved to cleaned_kk_data.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "languages = [\"en\", \"zh\", \"es\", \"ar\", \"fr\", \"ru\", \"pt\", \"de\", \"ja\", \"hi\", \"kk\"]\n",
    "\n",
    "for lang in languages:\n",
    "    process_language(lang)\n",
    "    # Append cleaned data to the main file\n",
    "    cleaned_file = f\"cleaned_{lang}_data.txt\"\n",
    "    if os.path.exists(cleaned_file):\n",
    "        os.system(f\"cat {cleaned_file} >> all_languages_text.txt\")\n",
    "        # Remove the individual cleaned file to save space\n",
    "        os.remove(cleaned_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We retrain the model with enhanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to shuffle the data before training the model using utility funciton\n",
    "!shuf all_languages_text.txt > shuffled_all_languages_text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:   158942 lines\n",
      "Test set:    39736 lines\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "# Get the total number of lines and split the dataset\n",
    "!total_lines=$(wc -l < shuffled_all_languages_text.txt) && \\\n",
    "train_lines=$(echo \"$total_lines * 0.8 / 1\" | bc) && \\\n",
    "test_lines=$(echo \"$total_lines - $train_lines\" | bc) && \\\n",
    "head -n $train_lines shuffled_all_languages_text.txt > train.txt && \\\n",
    "tail -n $test_lines shuffled_all_languages_text.txt > test.txt\n",
    "\n",
    "# Verify the split\n",
    "!echo \"Train set: $(wc -l < train.txt) lines\"\n",
    "!echo \"Test set: $(wc -l < test.txt) lines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  402140\n",
      "Number of labels: 11\n",
      "Progress: 100.0% words/sec/thread: 1531878 lr:  0.000000 avg.loss:  0.160834 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "!fastText-0.9.2/fasttext supervised -input train.txt -output langdetect -dim 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t39736\n",
      "P@1\t0.96\n",
      "R@1\t0.96\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "!fastText-0.9.2/fasttext test langdetect.bin test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We trained improved model with enhanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  402140\n",
      "Number of labels: 11\n",
      "Progress: 100.0% words/sec/thread:  890205 lr:  0.000000 avg.loss:  0.030108 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./fastText-0.9.2/fasttext', 'supervised', '-input', 'train.txt', '-output', 'langdetect', '-dim', '16', '-epoch', '15', '-lr', '1.0', '-loss', 'hs', '-minn', '2', '-maxn', '4', '-wordNgrams', '2'], returncode=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retraining the model with all improvements applied\n",
    "import subprocess\n",
    "\n",
    "# Command to run FastText with all the improvements applied\n",
    "command = [\n",
    "    './fastText-0.9.2/fasttext', 'supervised',\n",
    "    '-input', 'train.txt',        # Training data\n",
    "    '-output', 'langdetect',      # Output model name prefix\n",
    "    '-dim', '16',                 # Set vector dimension to 16\n",
    "    '-epoch', '15',               # Increase the number of epochs to 15\n",
    "    '-lr', '1.0',                 # Increase the learning rate to 1.0\n",
    "    '-loss', 'hs',                # Use hierarchical softmax loss function\n",
    "    '-minn', '2', '-maxn', '4',   # Use character n-grams from 2 to 4 characters (subword features)\n",
    "    '-wordNgrams', '2'            # Include word bigrams (word n-grams of length 2)\n",
    "]\n",
    "\n",
    "# Run the command using subprocess\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t39736\n",
      "P@1\t0.982\n",
      "R@1\t0.982\n"
     ]
    }
   ],
   "source": [
    "# Testing the improved model on the validation set\n",
    "!fastText-0.9.2/fasttext test langdetect.bin test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Tatoeba Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2024-10-11 14:39:03--  https://downloads.tatoeba.org/exports/sentences.tar.bz2\n",
      "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
      "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 195102325 (186M) [application/octet-stream]\n",
      "Saving to: 'sentences.tar.bz2'\n",
      "\n",
      "sentences.tar.bz2   100%[===================>] 186.06M  7.32MB/s    in 40s     \n",
      "\n",
      "2024-10-11 14:39:45 (4.63 MB/s) - 'sentences.tar.bz2' saved [195102325/195102325]\n",
      "\n",
      "bunzip2: Output file sentences.tar already exists.\n",
      "x sentences.csv\n"
     ]
    }
   ],
   "source": [
    "# Downloading files from Tatoeba\n",
    "!wget http://downloads.tatoeba.org/exports/sentences.tar.bz2\n",
    "!bunzip2 sentences.tar.bz2\n",
    "!tar xvf sentences.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data for fastText\n",
    "!awk -F\"\\t\" '{print \"__label__\"$2\" \"$3}' sentences.csv | shuf > all.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tatoeba data to previous data all_languages_text.txt\n",
    "!cat all.txt >> all_languages_text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to shuffle the data before training the model using utility funciton\n",
    "!shuf all_languages_text.txt > shuffled_all_languages_text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  10003348 lines\n",
      "Test set:  2500838 lines\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "# Get the total number of lines and split the dataset\n",
    "!total_lines=$(wc -l < shuffled_all_languages_text.txt) && \\\n",
    "train_lines=$(echo \"$total_lines * 0.8 / 1\" | bc) && \\\n",
    "test_lines=$(echo \"$total_lines - $train_lines\" | bc) && \\\n",
    "head -n $train_lines shuffled_all_languages_text.txt > train.txt && \\\n",
    "tail -n $test_lines shuffled_all_languages_text.txt > test.txt\n",
    "\n",
    "# Verify the split\n",
    "!echo \"Train set: $(wc -l < train.txt) lines\"\n",
    "!echo \"Test set: $(wc -l < test.txt) lines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 82M words\n",
      "Number of words:  4244081\n",
      "Number of labels: 429\n",
      "Progress: 100.0% words/sec/thread:  246743 lr:  0.000000 avg.loss:  0.195939 ETA:   0h 0m 0sss 92.8% words/sec/thread:  246688 lr:  0.007186 avg.loss:  0.204689 ETA:   0h 0m10s0h 0m 5s\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "!fastText-0.9.2/fasttext supervised -input train.txt -output langdetect -dim 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t2500834\n",
      "P@1\t0.946\n",
      "R@1\t0.946\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "!fastText-0.9.2/fasttext test langdetect.bin test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 82M words\n",
      "Number of words:  4244081\n",
      "Number of labels: 429\n",
      "Progress: 100.0% words/sec/thread: 1078336 lr:  0.000000 avg.loss:  0.066381 ETA:   0h 0m 0s32.7% words/sec/thread: 1116410 lr:  0.672896 avg.loss:  0.118281 ETA:   0h 1m 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./fastText-0.9.2/fasttext', 'supervised', '-input', 'train.txt', '-output', 'langdetect', '-dim', '16', '-epoch', '15', '-lr', '1.0', '-loss', 'hs', '-minn', '2', '-maxn', '4', '-wordNgrams', '2'], returncode=0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retraining the model with all improvements applied\n",
    "import subprocess\n",
    "\n",
    "# Command to run FastText with all the improvements applied\n",
    "command = [\n",
    "    './fastText-0.9.2/fasttext', 'supervised',\n",
    "    '-input', 'train.txt',        # Training data\n",
    "    '-output', 'langdetect',      # Output model name prefix\n",
    "    '-dim', '16',                 # Set vector dimension to 16\n",
    "    '-epoch', '15',               # Increase the number of epochs to 15\n",
    "    '-lr', '1.0',                 # Increase the learning rate to 1.0\n",
    "    '-loss', 'hs',                # Use hierarchical softmax loss function\n",
    "    '-minn', '2', '-maxn', '4',   # Use character n-grams from 2 to 4 characters (subword features)\n",
    "    '-wordNgrams', '2'            # Include word bigrams (word n-grams of length 2)\n",
    "]\n",
    "\n",
    "# Run the command using subprocess\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t2500834\n",
      "P@1\t0.972\n",
      "R@1\t0.972\n"
     ]
    }
   ],
   "source": [
    "# Testing the improved model on the validation set\n",
    "!fastText-0.9.2/fasttext test langdetect.bin test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing results with official model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-11 14:50:01--  https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.158.20.111, 108.158.20.43, 108.158.20.21, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.158.20.111|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 131266198 (125M) [application/octet-stream]\n",
      "Saving to: 'lid.176.bin.1'\n",
      "\n",
      "lid.176.bin.1       100%[===================>] 125.18M  11.2MB/s    in 12s     \n",
      "\n",
      "2024-10-11 14:50:14 (10.3 MB/s) - 'lid.176.bin.1' saved [131266198/131266198]\n",
      "\n",
      "--2024-10-11 14:50:14--  https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.158.20.111, 108.158.20.43, 108.158.20.21, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.158.20.111|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 938013 (916K) [binary/octet-stream]\n",
      "Saving to: 'lid.176.ftz.1'\n",
      "\n",
      "lid.176.ftz.1       100%[===================>] 916.03K  --.-KB/s    in 0.07s   \n",
      "\n",
      "2024-10-11 14:50:15 (12.5 MB/s) - 'lid.176.ftz.1' saved [938013/938013]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Downloading the Pre-trained Models\n",
    "# Download the larger model\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
    "\n",
    "# Download the compressed model\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t57651\n",
      "P@1\t0.915\n",
      "R@1\t0.915\n"
     ]
    }
   ],
   "source": [
    "# Testing the Pre-trained Models\n",
    "# Testing the larger model\n",
    "!fastText-0.9.2/fasttext test lid.176.bin test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t57651\n",
      "P@1\t0.871\n",
      "R@1\t0.871\n"
     ]
    }
   ],
   "source": [
    "# Testing the compressed model\n",
    "!fastText-0.9.2/fasttext test lid.176.ftz test.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
